{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRchzKezXwOfroIi5wLW76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stellaevat/ontology-mapping/blob/main/colabs/bi_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg1BOxf1KlAU"
      },
      "outputs": [],
      "source": [
        "!pip install pronto transformers[torch] datasets evaluate faiss-gpu\\\n",
        "&& pip install accelerate -U \\\n",
        "&& wget -O doid.obo https://gla-my.sharepoint.com/:u:/g/personal/2526934t_student_gla_ac_uk/EfUC_RdrfZdOsOrtmNATjuoBPDaIkSTUMyxJXyO2KKC6yw?download=1 \\\n",
        "&& wget -O ncit.obo https://gla-my.sharepoint.com/:u:/g/personal/2526934t_student_gla_ac_uk/ETmaJIC0fAlItdsp8WQxS_wBzKN_6x08EZrtsOxVnbzvSg?download=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\""
      ],
      "metadata": {
        "id": "RQPDnoD3mcxf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pronto\n",
        "import evaluate\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import copy, deepcopy\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
        "from transformers import get_scheduler, AutoTokenizer, AutoModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "YFVyasHU3Hk7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncit = pronto.Ontology(\"ncit.obo\")\n",
        "doid = pronto.Ontology(\"doid.obo\")"
      ],
      "metadata": {
        "id": "xbIac4iK3ZeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get subsumptions from CSV file to a dictionary\n",
        "\n",
        "def get_mappings_from_file(filename):\n",
        "  mappings = {}\n",
        "  with open(filename) as f:\n",
        "    for line in f:\n",
        "      source_id, target_id = line.strip().split(',')\n",
        "      mappings[source_id] = target_id\n",
        "  return mappings"
      ],
      "metadata": {
        "id": "SwXk14NN4MtF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equiv_doid2ncit = get_mappings_from_file(\"equiv_doid2ncit.csv\")\n",
        "equiv_ncit2doid = get_mappings_from_file(\"equiv_ncit2doid.csv\")\n",
        "subs_doid2ncit = get_mappings_from_file(\"subs_doid2ncit.csv\")\n",
        "subs_ncit2doid = get_mappings_from_file(\"subs_ncit2doid.csv\")\n",
        "neg_subs_doid2ncit = get_mappings_from_file(\"neg_subs_doid2ncit.csv\")\n",
        "neg_subs_ncit2doid = get_mappings_from_file(\"neg_subs_ncit2doid.csv\")"
      ],
      "metadata": {
        "id": "6UQVGr1YGrUF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert relations to sentences\n",
        "\n",
        "> Currently considering parents, children & siblings for conceptual reasons, but could also take 'n-hop' appraoch, e.g. 1-hop only with parents and children, or 2-hop to include grandparents, grandchildren and siblings.\n",
        "\n",
        "> How do I incorporate the desired mapping for training? Should I incorporate both all this AND target info, or too much? Could be SELF + desired relatives instead, or SELF + PARENT + DESIRED PARENT, etc."
      ],
      "metadata": {
        "id": "4kBAYe8J3pRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_markers = [\"[SUB]\", \"[/SUB]\", \"[SUP]\", \"[/SUP]\"]\n",
        "sep_token = \"[SEP]\"\n",
        "cls_token = \"[CLS]\""
      ],
      "metadata": {
        "id": "UUiDKZI5dpFJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentence from the given entity, containing its direct parents & siblings\n",
        "\n",
        "def get_sentence(entity_id, onto):\n",
        "  sub_in, sub_out, sup_in, sup_out = entity_markers\n",
        "\n",
        "  subsumer = onto.get_term(entity_id)\n",
        "  supersumers = list(subsumer.superclasses(distance=1, with_self=False))\n",
        "\n",
        "  sentence = [sub_in, subsumer.name, sub_out]\n",
        "  for supersumer in supersumers:\n",
        "    sentence.extend([sup_in, supersumer.name, sup_out])\n",
        "\n",
        "  return \"\".join(sentence)"
      ],
      "metadata": {
        "id": "55KpYNDq6A3h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_id = \"DOID:0014667\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
        "# tokenizer.add_tokens(entity_markers)\n",
        "\n",
        "sentence = doid.get_term(source_id).name\n",
        "tokenized = tokenizer(sentence)\n",
        "\n",
        "print(sentence)\n",
        "tokenizer.convert_ids_to_tokens(tokenized['input_ids'])"
      ],
      "metadata": {
        "id": "QubatHjc00Gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb06abd-1d31-4e09-a6ca-86ccae9c76d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disease of metabolism\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'disease', 'of', 'metabolism', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collate input dataset"
      ],
      "metadata": {
        "id": "P9cDB8uOQeGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_labelled_biencoder_samples(subs, negsubs, source_onto, target_onto):\n",
        "  random.seed(3)\n",
        "  source_samples = []\n",
        "  target_samples = []\n",
        "  labels = []\n",
        "\n",
        "  pairs = list(subs.items()) + list(negsubs.items())\n",
        "  ones_and_zeros = [1] * len(subs) + [0] * len(negsubs)\n",
        "  labelled_pairs = list(zip(ones_and_zeros, pairs))\n",
        "  random.shuffle(labelled_pairs)\n",
        "\n",
        "  for label, (source_id, target_id) in tqdm(labelled_pairs):\n",
        "    if source_id not in source_onto.terms() or target_id not in target_onto.terms():\n",
        "      continue\n",
        "    source_sentence = source_onto.get_term(source_id).name\n",
        "    target_sentence = target_onto.get_term(target_id).name\n",
        "    # if source_onto.get_term(source_id).definition:\n",
        "    #   source_sentence += \" \" + source_onto.get_term(source_id).definition\n",
        "    # if target_onto.get_term(target_id).definition:\n",
        "    #   target_sentence += \" \" + target_onto.get_term(target_id).definition\n",
        "    if source_sentence and target_sentence:\n",
        "      source_samples.append(source_sentence)\n",
        "      target_samples.append(target_sentence)\n",
        "      labels.append(label)\n",
        "\n",
        "  print()\n",
        "  return source_samples, target_samples, labels"
      ],
      "metadata": {
        "id": "Ssj9hefVvSQg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_samples, target_samples, labels = generate_labelled_biencoder_samples(subs_doid2ncit, neg_subs_doid2ncit, doid, ncit)\n",
        "print(f\"Samples: {len(source_samples)}, {len(target_samples)}\")\n",
        "print(f\"Labels: {len(labels)}\")"
      ],
      "metadata": {
        "id": "DmD99KQ_hWbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f771e08-236c-4328-8285-13ab9478c74b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3766/3766 [00:00<00:00, 53919.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Samples: 3765, 3765\n",
            "Labels: 3765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_source_target(Xi, source_samples, target_samples):\n",
        "  X_source = np.array([source_samples[i] for i in Xi])\n",
        "  X_target = np.array([target_samples[i] for i in Xi])\n",
        "  return X_source, X_target"
      ],
      "metadata": {
        "id": "H_CahO_vC5kY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_dataset(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "  dataset_train = Dataset.from_dict({'sample':X_train, 'label':y_train})\n",
        "  dataset_val = Dataset.from_dict({'sample':X_val, 'label':y_val})\n",
        "  dataset_test = Dataset.from_dict({'sample':X_test, 'label':y_test})\n",
        "  dataset = DatasetDict({'train':dataset_train,'val':dataset_val,'test':dataset_test})\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "00blfsjpIDl5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xi = np.arange(len(source_samples))\n",
        "y = np.array(labels)\n",
        "Xi_train_val, Xi_test, y_train_val, y_test = train_test_split(Xi, y, test_size=0.2, random_state=3)\n",
        "Xi_train, Xi_val, y_train, y_val = train_test_split(Xi_train_val, y_train_val, test_size=0.25, random_state=3)\n",
        "\n",
        "X_source_train, X_target_train = filter_source_target(Xi_train, source_samples, target_samples)\n",
        "X_source_val, X_target_val = filter_source_target(Xi_val, source_samples, target_samples)\n",
        "X_source_test, X_target_test = filter_source_target(Xi_test, source_samples, target_samples)\n",
        "\n",
        "source_data = collate_dataset(X_source_train, X_source_val, X_source_test, y_train, y_val, y_test)\n",
        "target_data = collate_dataset(X_target_train, X_target_val, X_target_test, y_train, y_val, y_test)"
      ],
      "metadata": {
        "id": "ktcbbfRmFwuO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train end-to-end BERT-based bi-encoder"
      ],
      "metadata": {
        "id": "Mwy-uRdLOY69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiEncoderForSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, model_name, num_labels, id2label=None, label2id=None, token_embeddings_size=None, hidden_layer=-1):\n",
        "    super().__init__()\n",
        "    self.source_model = AutoModel.from_pretrained(model_name)\n",
        "    self.target_model = AutoModel.from_pretrained(model_name)\n",
        "    if token_embeddings_size:\n",
        "      self.source_model.resize_token_embeddings(token_embeddings_size)\n",
        "      self.target_model.resize_token_embeddings(token_embeddings_size)\n",
        "    self.source_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    self.target_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    self.num_labels = num_labels\n",
        "    self.hidden_layer = hidden_layer\n",
        "\n",
        "    self.linear = torch.nn.Linear(32, num_labels)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.similarity = torch.nn.CosineSimilarity(dim=-1)\n",
        "    self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      s_input_ids=None, t_input_ids=None,\n",
        "      s_attention_mask=None, t_attention_mask=None,\n",
        "      s_token_type_ids=None, t_token_type_ids=None,\n",
        "      s_position_ids=None, t_position_ids=None,\n",
        "      s_head_mask=None, t_head_mask=None,\n",
        "      s_inputs_embeds=None, t_inputs_embeds=None,\n",
        "      labels=None\n",
        "    ):\n",
        "\n",
        "    source_outputs = self.source_model(\n",
        "      s_input_ids,\n",
        "      attention_mask=s_attention_mask,\n",
        "      token_type_ids=s_token_type_ids,\n",
        "      position_ids=s_position_ids,\n",
        "      head_mask=s_head_mask,\n",
        "      inputs_embeds=s_inputs_embeds,\n",
        "    )\n",
        "\n",
        "    target_outputs = self.target_model(\n",
        "      t_input_ids,\n",
        "      attention_mask=t_attention_mask,\n",
        "      token_type_ids=t_token_type_ids,\n",
        "      position_ids=t_position_ids,\n",
        "      head_mask=t_head_mask,\n",
        "      inputs_embeds=t_inputs_embeds,\n",
        "    )\n",
        "\n",
        "    pooled_source_outputs = self.dropout(source_outputs[1])\n",
        "    pooled_target_outputs = self.dropout(target_outputs[1])\n",
        "\n",
        "    logits = self.similarity(pooled_source_outputs, pooled_target_outputs)\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss = self.loss(logits.view(-1), labels.view(-1).float())\n",
        "\n",
        "    return SequenceClassifierOutput(loss=loss, logits=logits)\n",
        "\n",
        "  def get_source_model_outputs(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
        "    source_outputs = self.source_model(\n",
        "      input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids=token_type_ids\n",
        "    )\n",
        "    return source_outputs[1]\n",
        "\n",
        "  def get_target_model_outputs(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
        "    target_outputs = self.target_model(\n",
        "      input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids=token_type_ids\n",
        "    )\n",
        "    return target_outputs[1]"
      ],
      "metadata": {
        "id": "xKdO0rN_wJsY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_determinism(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.use_deterministic_algorithms(True)\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "1EeqaVxWfb_6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_tokenized_dataset(dataset, tokenizer):\n",
        "  preprocess_tokenize = lambda data: tokenizer(data[\"sample\"], padding=\"longest\")\n",
        "  tokenized_data = dataset.map(preprocess_tokenize, batched=True, batch_size=len(dataset[\"train\"][\"sample\"]))\n",
        "  tokenized_data = tokenized_data.remove_columns([\"sample\"])\n",
        "  tokenized_data = tokenized_data.rename_column(\"label\", \"labels\")\n",
        "  tokenized_data.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "9ju9Nf53gMPJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_results(epoch, loss, metrics):\n",
        "  print(f\"\\n\\nEPOCH {epoch}\\n\")\n",
        "  print(f\"Training loss: {loss}\")\n",
        "  pprint(metrics)\n",
        "  print()"
      ],
      "metadata": {
        "id": "wOpizfqyM4Qy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_biencoder(entity_markers=[]):\n",
        "  pretrained = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(pretrained)\n",
        "  tokenizer.add_tokens(entity_markers)\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "  model = BiEncoderForSequenceClassification(pretrained, num_labels=1, token_embeddings_size=len(tokenizer))\n",
        "  return model, tokenizer\n",
        "\n",
        "def evaluate_biencoder(model, tokenized_source, tokenized_target, batch_size=32):\n",
        "  eval_dataloader_index = DataLoader(Dataset.from_dict({'index' : range(len(tokenized_source[\"val\"]))}), batch_size=batch_size)\n",
        "  metrics = [evaluate.load(\"accuracy\"), evaluate.load(\"precision\"), evaluate.load('recall'), evaluate.load('f1')]\n",
        "\n",
        "  model.eval()\n",
        "  for batch in eval_dataloader_index:\n",
        "    batch_index = list(batch[\"index\"])\n",
        "    source_batch = tokenized_source[\"val\"][batch_index]\n",
        "    target_batch = tokenized_target[\"val\"][batch_index]\n",
        "    labels = source_batch[\"labels\"]\n",
        "\n",
        "    source_batch = {\"s_\" + k: v.to(device) for (k, v) in source_batch.items() if k != \"labels\"}\n",
        "    target_batch = {\"t_\" + k: v.to(device) for (k, v) in target_batch.items() if k != \"labels\"}\n",
        "    params = source_batch | target_batch\n",
        "    params[\"labels\"] = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**params)\n",
        "\n",
        "    logits = outputs.logits.cpu()\n",
        "    predictions = np.where(logits.squeeze() >= 0.95, 1, 0)\n",
        "    for metric in metrics:\n",
        "      metric.add_batch(predictions=predictions, references=labels.cpu())\n",
        "\n",
        "  metric_dict = metrics[0].compute()\n",
        "  for metric in metrics[1:]:\n",
        "    metric_dict.update(metric.compute(average='macro'))\n",
        "\n",
        "  return metric_dict\n",
        "\n",
        "def train_biencoder(model, tokenized_source, tokenized_target, learning_rate=1e-5, epochs=4, batch_size=32):\n",
        "  train_dataloader_index = DataLoader(Dataset.from_dict({'index' : range(len(tokenized_source[\"train\"]))}), shuffle=True, batch_size=batch_size)\n",
        "  num_training_steps = epochs * len(train_dataloader_index)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "  scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "  progress_bar = tqdm(range(num_training_steps), position=0, leave=True)\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(1, epochs+1):\n",
        "    for i, batch in enumerate(train_dataloader_index):\n",
        "      batch_index = list(batch[\"index\"])\n",
        "      source_batch = tokenized_source[\"train\"][batch_index]\n",
        "      target_batch = tokenized_target[\"train\"][batch_index]\n",
        "      labels = source_batch[\"labels\"]\n",
        "\n",
        "      source_batch = {\"s_\" + k: v.to(device) for (k, v) in source_batch.items() if k != \"labels\"}\n",
        "      target_batch = {\"t_\" + k: v.to(device) for (k, v) in target_batch.items() if k != \"labels\"}\n",
        "      params = source_batch | target_batch\n",
        "      params[\"labels\"] = labels.to(device)\n",
        "\n",
        "      outputs = model(**params)\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "      progress_bar.update(1)\n",
        "\n",
        "    metrics = evaluate_biencoder(model, tokenized_source, tokenized_target, batch_size=batch_size)\n",
        "    show_results(epoch, loss, metrics)"
      ],
      "metadata": {
        "id": "2QFIQmGhGda9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "full_determinism(seed=3)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model, tokenizer = setup_biencoder()\n",
        "tokenized_source = format_tokenized_dataset(source_data, tokenizer)\n",
        "tokenized_target = format_tokenized_dataset(target_data, tokenizer)\n",
        "model.to(device)\n",
        "\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "yz4Gj-3cGv58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_biencoder(model, tokenized_source, tokenized_target)"
      ],
      "metadata": {
        "id": "-IebuX4BGz0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4003d3-f385-4daa-bd46-d89cffa704d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 71/284 [00:38<01:56,  1.83it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1\n",
            "\n",
            "Training loss: 0.6485085487365723\n",
            "{'accuracy': 0.44754316069057104,\n",
            " 'f1': 0.3091743119266055,\n",
            " 'precision': 0.22377158034528552,\n",
            " 'recall': 0.5}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 142/284 [01:22<01:14,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 2\n",
            "\n",
            "Training loss: 0.4714702367782593\n",
            "{'accuracy': 0.46082337317397076,\n",
            " 'f1': 0.33551121544079293,\n",
            " 'precision': 0.7267833109017496,\n",
            " 'recall': 0.5120192307692307}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 213/284 [02:07<00:37,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 3\n",
            "\n",
            "Training loss: 0.3488360047340393\n",
            "{'accuracy': 0.5564409030544488,\n",
            " 'f1': 0.4989840313635494,\n",
            " 'precision': 0.7511177347242921,\n",
            " 'recall': 0.5985576923076923}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 284/284 [02:57<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 4\n",
            "\n",
            "Training loss: 0.40581077337265015\n",
            "{'accuracy': 0.6268260292164675,\n",
            " 'f1': 0.5985021128671427,\n",
            " 'precision': 0.7690776376907764,\n",
            " 'recall': 0.6619778589363159}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faiss"
      ],
      "metadata": {
        "id": "VEH4XQTPOV7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del ncit\n",
        "del doid\n",
        "# model.to(torch.device(\"cpu\"))"
      ],
      "metadata": {
        "id": "neEMZu_DoL1L"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences_from_ontology(onto):\n",
        "  sentences = []\n",
        "  for term in onto.terms():\n",
        "    sentence = term.name\n",
        "    # if term.definition:\n",
        "    #   sentence += \" \" + term.definition\n",
        "    if sentence:\n",
        "      sentences.append(sentence)\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "We4JrT8OOZN5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queries = get_sentences_from_ontology(doid)\n",
        "# database = get_sentences_from_ontology(ncit)\n",
        "queries = X_source_train[y_train == 1]\n",
        "database = X_target_train[y_train == 1]"
      ],
      "metadata": {
        "id": "QVlel1zmQXdZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "q_size = 100\n",
        "db_size = 100"
      ],
      "metadata": {
        "id": "VLTbhwwrCCfD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer(list(queries[offset : offset + q_size]) + list(database[offset : offset + db_size]), padding=\"longest\")\n",
        "for (k, v) in tokenized.items():\n",
        "  tokenized[k] = torch.tensor(v, dtype=torch.int)\n",
        "\n",
        "faiss_device = torch.device(\"cpu\")\n",
        "tokenized_source = {k : v[:q_size].to(device) for (k, v) in tokenized.items()}\n",
        "tokenized_target = {k : v[q_size:].to(device) for (k, v) in tokenized.items()}"
      ],
      "metadata": {
        "id": "mYhBIqNLW9RB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_queries = model.get_source_model_outputs(**tokenized_source)\n",
        "tokenized_database = model.get_source_model_outputs(**tokenized_target)"
      ],
      "metadata": {
        "id": "aRJNNxneTrgP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 64\n",
        "# tokenized_database_lst = []\n",
        "# for batch_start in range(0, db_size, batch_size):\n",
        "#   batch_end = min(batch_start + batch_size, db_size)\n",
        "#   batch = {k : v[batch_start : batch_end] for (k, v) in tokenized_target.items()}\n",
        "#   tokenized_batch = model.get_target_model_outputs(**batch)\n",
        "#   tokenized_database_lst.append(tokenized_batch)\n",
        "\n",
        "# tokenized_database = torch.cat(tokenized_database_lst, 0)"
      ],
      "metadata": {
        "id": "vIIJczkK1zYH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = len(tokenized_database[0])\n",
        "xq = np.array(tokenized_queries.cpu().detach().numpy(), dtype=np.single)\n",
        "xb = np.array(tokenized_database.cpu().detach().numpy(), dtype=np.single)\n",
        "\n",
        "print(d, xq.shape, xb.shape)"
      ],
      "metadata": {
        "id": "PDsJZoPr-Kss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7360a72-fe94-47ae-b44d-c5c22e60efbf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768 (100, 768) (100, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = faiss.StandardGpuResources()  # use a single GPU\n",
        "\n",
        "index_flat = faiss.IndexFlatIP(d)   # build a flat (CPU) index\n",
        "\n",
        "index_flat.add(xb)                  # add vectors to the index\n",
        "# print(index_flat.ntotal)\n",
        "\n",
        "k = 100                              # we want to see 10 nearest neighbors\n",
        "D, I = index_flat.search(xq, k)     # actual search\n",
        "# print(I[:5])                        # neighbors of the 5 first queries\n",
        "# print(D[:5])                        # similarities of the 5 first queries"
      ],
      "metadata": {
        "id": "JfhazGnF6tce"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = []\n",
        "for i in range(q_size):\n",
        "  source, target = queries[offset + i], database[offset + i]\n",
        "  # print(\"\\nSource:\", source)\n",
        "  # print(\"Target:\", target)\n",
        "\n",
        "  for n, index in enumerate(I[i]):\n",
        "    # print(n + 1, database[offset + index])\n",
        "    if database[offset + index] == target:\n",
        "      ranks.append(n + 1)\n",
        "      # print(\"Rank found:\", n + 1)\n",
        "      break\n",
        "    # print(\"Not found\")"
      ],
      "metadata": {
        "id": "RE5GxBXRgMbt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(ranks)\n",
        "print(f\"In first result: {ranks.count(1)}\")\n",
        "print(f\"In first 10 results: {len([r for r in ranks if r <= 10])}\")\n",
        "print(f\"MRR: {np.mean(1 / np.array(ranks))}\")"
      ],
      "metadata": {
        "id": "Z37GxccYwYS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "8c95cae4-9f31-4d26-fd9b-c0f815d679fc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In first result: 25\n",
            "In first 10 results: 52\n",
            "MRR: 0.3531573872913604\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAchElEQVR4nO3df3DU9Z348VdCSMBCNk2URM5EaGsbrcVTqJDq3bWaO0oZqyXttA5t0WPa0YuekLlr5XrqtXc2zDnjrw7qXcfidCqlZabaYlsdJ7ZYpwEhiqf1pHriwRUTrnWSAJbAkc/3j++50xTsEbJx3yyPx8zOsJ/PJ5998Q5DnrO7n2xZlmVZAAAkpLzYAwAA/D6BAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIqij3A7xseHo5du3bF1KlTo6ysrNjjAABHIcuy2LNnT0yfPj3Ky8f+/EdygbJr165obGws9hgAwDHYuXNnnHbaaWM+T3KBMnXq1Ij4/3/B6urqIk8DAByNwcHBaGxszP8cH6vkAuWNl3Wqq6sFCgAcZwr19gxvkgUAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkVBR7gLfajOt/WOwRRu2VlQuLPQIAvKU8gwIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkZ1SB8g//8A9RVlY24tbc3Jzfv3///mhvb4+6urqYMmVKtLW1RV9fX8GHBgBK26ifQXnve98br776av72xBNP5PctX7481q9fH+vWrYsNGzbErl27YtGiRQUdGAAofaP+LJ6KiopoaGg4bPvAwEDce++9sWbNmrjooosiImL16tVx5plnxsaNG2PevHljnxYAOCGM+hmUF198MaZPnx7veMc7YvHixbFjx46IiOjp6YmDBw9Ga2tr/tjm5uZoamqK7u7uNz3f0NBQDA4OjrgBACe2UQXK3Llz47777ouHH3447r777ti+fXv8yZ/8SezZsyd6e3ujsrIyampqRnxNfX199Pb2vuk5Ozs7I5fL5W+NjY3H9BcBAErHqF7iWbBgQf7Ps2bNirlz58bpp58e3/3ud2Py5MnHNMCKFSuio6Mjf39wcFCkAMAJbkyXGdfU1MS73/3ueOmll6KhoSEOHDgQ/f39I47p6+s74ntW3lBVVRXV1dUjbgDAiW1MgbJ37974j//4jzj11FNj9uzZMXHixOjq6srv37ZtW+zYsSNaWlrGPCgAcOIY1Us8f/M3fxOXXHJJnH766bFr16646aabYsKECXH55ZdHLpeLpUuXRkdHR9TW1kZ1dXVce+210dLS4goeAGBURhUo//Vf/xWXX355/OY3v4lTTjklLrzwwti4cWOccsopERFx2223RXl5ebS1tcXQ0FDMnz8/7rrrrnEZHAAoXWVZlmXFHuJ3DQ4ORi6Xi4GBgXF5P8qM639Y8HOOt1dWLiz2CADwBxX657fP4gEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASM6YAmXlypVRVlYWy5Yty2/bv39/tLe3R11dXUyZMiXa2tqir69vrHMCACeQYw6UzZs3x7/8y7/ErFmzRmxfvnx5rF+/PtatWxcbNmyIXbt2xaJFi8Y8KABw4jimQNm7d28sXrw4vv71r8fb3/72/PaBgYG4995749Zbb42LLrooZs+eHatXr46f//znsXHjxoINDQCUtmMKlPb29li4cGG0traO2N7T0xMHDx4csb25uTmampqiu7t7bJMCACeMitF+wdq1a+Opp56KzZs3H7avt7c3Kisro6amZsT2+vr66O3tPeL5hoaGYmhoKH9/cHBwtCMBACVmVM+g7Ny5M6677rq4//77Y9KkSQUZoLOzM3K5XP7W2NhYkPMCAMevUQVKT09P7N69O84777yoqKiIioqK2LBhQ9x5551RUVER9fX1ceDAgejv7x/xdX19fdHQ0HDEc65YsSIGBgbyt507dx7zXwYAKA2jeonn4osvjmeffXbEtiuvvDKam5vji1/8YjQ2NsbEiROjq6sr2traIiJi27ZtsWPHjmhpaTniOauqqqKqquoYxwcAStGoAmXq1Klx9tlnj9j2tre9Lerq6vLbly5dGh0dHVFbWxvV1dVx7bXXRktLS8ybN69wUwMAJW3Ub5L9v9x2221RXl4ebW1tMTQ0FPPnz4+77rqr0A8DAJSwsizLsmIP8bsGBwcjl8vFwMBAVFdXF/z8M67/YcHPOd5eWbmw2CMAwB9U6J/fPosHAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASM6oAuXuu++OWbNmRXV1dVRXV0dLS0v8+Mc/zu/fv39/tLe3R11dXUyZMiXa2tqir6+v4EMDAKVtVIFy2mmnxcqVK6Onpye2bNkSF110UVx66aXxi1/8IiIili9fHuvXr49169bFhg0bYteuXbFo0aJxGRwAKF1lWZZlYzlBbW1t3HLLLfHxj388TjnllFizZk18/OMfj4iIF154Ic4888zo7u6OefPmHdX5BgcHI5fLxcDAQFRXV49ltCOacf0PC37O8fbKyoXFHgEA/qBC//w+5vegHDp0KNauXRv79u2LlpaW6OnpiYMHD0Zra2v+mObm5mhqaoru7u43Pc/Q0FAMDg6OuAEAJ7ZRB8qzzz4bU6ZMiaqqqrjqqqvigQceiLPOOit6e3ujsrIyampqRhxfX18fvb29b3q+zs7OyOVy+VtjY+Oo/xIAQGkZdaC85z3via1bt8amTZvi6quvjiVLlsTzzz9/zAOsWLEiBgYG8redO3ce87kAgNJQMdovqKysjHe9610RETF79uzYvHlz3HHHHfHJT34yDhw4EP39/SOeRenr64uGhoY3PV9VVVVUVVWNfnIAoGSN+fegDA8Px9DQUMyePTsmTpwYXV1d+X3btm2LHTt2REtLy1gfBgA4gYzqGZQVK1bEggULoqmpKfbs2RNr1qyJn/70p/HII49ELpeLpUuXRkdHR9TW1kZ1dXVce+210dLSctRX8AAARIwyUHbv3h2f/exn49VXX41cLhezZs2KRx55JP78z/88IiJuu+22KC8vj7a2thgaGor58+fHXXfdNS6DAwCla8y/B6XQ/B6Uw/k9KACkLpnfgwIAMF4ECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAckYVKJ2dnfH+978/pk6dGtOmTYvLLrsstm3bNuKY/fv3R3t7e9TV1cWUKVOira0t+vr6Cjo0AFDaRhUoGzZsiPb29ti4cWM8+uijcfDgwfiLv/iL2LdvX/6Y5cuXx/r162PdunWxYcOG2LVrVyxatKjggwMApatiNAc//PDDI+7fd999MW3atOjp6Yk//dM/jYGBgbj33ntjzZo1cdFFF0VExOrVq+PMM8+MjRs3xrx58wo3OQBQssb0HpSBgYGIiKitrY2IiJ6enjh48GC0trbmj2lubo6mpqbo7u4+4jmGhoZicHBwxA0AOLEdc6AMDw/HsmXL4oILLoizzz47IiJ6e3ujsrIyampqRhxbX18fvb29RzxPZ2dn5HK5/K2xsfFYRwIASsQxB0p7e3s899xzsXbt2jENsGLFihgYGMjfdu7cOabzAQDHv1G9B+UN11xzTTz00EPx+OOPx2mnnZbf3tDQEAcOHIj+/v4Rz6L09fVFQ0PDEc9VVVUVVVVVxzIGAFCiRvUMSpZlcc0118QDDzwQjz32WMycOXPE/tmzZ8fEiROjq6srv23btm2xY8eOaGlpKczEAEDJG9UzKO3t7bFmzZr4/ve/H1OnTs2/rySXy8XkyZMjl8vF0qVLo6OjI2pra6O6ujquvfbaaGlpcQUPAHDURhUod999d0REfPCDHxyxffXq1XHFFVdERMRtt90W5eXl0dbWFkNDQzF//vy46667CjIsAHBiGFWgZFn2fx4zadKkWLVqVaxateqYhwIATmw+iwcASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAklNR7AEAUjfj+h8We4Rj8srKhcUeAY6ZZ1AAgOSMOlAef/zxuOSSS2L69OlRVlYWDz744Ij9WZbFjTfeGKeeempMnjw5Wltb48UXXyzUvADACWDUgbJv374455xzYtWqVUfc/8///M9x5513xj333BObNm2Kt73tbTF//vzYv3//mIcFAE4Mo34PyoIFC2LBggVH3JdlWdx+++3x93//93HppZdGRMQ3v/nNqK+vjwcffDA+9alPjW1aAOCEUND3oGzfvj16e3ujtbU1vy2Xy8XcuXOju7u7kA8FAJSwgl7F09vbGxER9fX1I7bX19fn9/2+oaGhGBoayt8fHBws5EgAwHGo6JcZd3Z2xpe//OVij5G04/ESR5c3AjAWBX2Jp6GhISIi+vr6Rmzv6+vL7/t9K1asiIGBgfxt586dhRwJADgOFTRQZs6cGQ0NDdHV1ZXfNjg4GJs2bYqWlpYjfk1VVVVUV1ePuAEAJ7ZRv8Szd+/eeOmll/L3t2/fHlu3bo3a2tpoamqKZcuWxT/90z/FGWecETNnzowbbrghpk+fHpdddlkh5wYAStioA2XLli3xoQ99KH+/o6MjIiKWLFkS9913X3zhC1+Iffv2xec///no7++PCy+8MB5++OGYNGlS4aYGAEraqAPlgx/8YGRZ9qb7y8rK4itf+Up85StfGdNgAMCJy2fxAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMmpKPYAlKYZ1/+w2COM2isrFxZ7BAD+l2dQAIDkCBQAIDkCBQBIjkABAJIjUACA5LiKB4BkuAKQN3gGBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCS4zJjOI65JJM/5Hj89wFv8AwKAJAcgQIAJEegAADJESgAQHIECgCQHIECACTHZcbwv1yS+dawzsDR8AwKAJAcgQIAJEegAADJESgAQHIECgCQHIECACTHZcYAMAbH46Xzx8OninsGBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOeMWKKtWrYoZM2bEpEmTYu7cufHkk0+O10MBACVmXALlO9/5TnR0dMRNN90UTz31VJxzzjkxf/782L1793g8HABQYsYlUG699db43Oc+F1deeWWcddZZcc8998RJJ50U3/jGN8bj4QCAElPwz+I5cOBA9PT0xIoVK/LbysvLo7W1Nbq7uw87fmhoKIaGhvL3BwYGIiJicHCw0KNFRMTw0Ovjcl4AOF6Mx8/YN86ZZVlBzlfwQPn1r38dhw4divr6+hHb6+vr44UXXjjs+M7Ozvjyl7982PbGxsZCjwYARETu9vE79549eyKXy435PEX/NOMVK1ZER0dH/v7w8HC89tprUVdXF2VlZcd83sHBwWhsbIydO3dGdXV1IUblKFn74rH2xWPti8faF8/vrv3UqVNjz549MX369IKcu+CBcvLJJ8eECROir69vxPa+vr5oaGg47Piqqqqoqqoasa2mpqZg81RXV/sHWyTWvnisffFY++Kx9sXzxtoX4pmTNxT8TbKVlZUxe/bs6Orqym8bHh6Orq6uaGlpKfTDAQAlaFxe4uno6IglS5bEnDlz4vzzz4/bb7899u3bF1deeeV4PBwAUGLGJVA++clPxn//93/HjTfeGL29vfHHf/zH8fDDDx/2xtnxVFVVFTfddNNhLx8x/qx98Vj74rH2xWPti2c8174sK9T1QAAABeKzeACA5AgUACA5AgUASI5AAQCSU7KBsmrVqpgxY0ZMmjQp5s6dG08++WSxRyopnZ2d8f73vz+mTp0a06ZNi8suuyy2bds24pj9+/dHe3t71NXVxZQpU6Ktre2wX+DH2K1cuTLKyspi2bJl+W3Wfvz86le/ik9/+tNRV1cXkydPjve9732xZcuW/P4sy+LGG2+MU089NSZPnhytra3x4osvFnHi0nDo0KG44YYbYubMmTF58uR45zvfGf/4j/844nNfrH1hPP7443HJJZfE9OnTo6ysLB588MER+49mnV977bVYvHhxVFdXR01NTSxdujT27t07ukGyErR27dqssrIy+8Y3vpH94he/yD73uc9lNTU1WV9fX7FHKxnz58/PVq9enT333HPZ1q1bs4985CNZU1NTtnfv3vwxV111VdbY2Jh1dXVlW7ZsyebNm5d94AMfKOLUpefJJ5/MZsyYkc2aNSu77rrr8tut/fh47bXXstNPPz274oorsk2bNmUvv/xy9sgjj2QvvfRS/piVK1dmuVwue/DBB7Nnnnkm++hHP5rNnDkz++1vf1vEyY9/N998c1ZXV5c99NBD2fbt27N169ZlU6ZMye644478Mda+MH70ox9lX/rSl7Lvfe97WURkDzzwwIj9R7POH/7wh7Nzzjkn27hxY/azn/0se9e73pVdfvnlo5qjJAPl/PPPz9rb2/P3Dx06lE2fPj3r7Ows4lSlbffu3VlEZBs2bMiyLMv6+/uziRMnZuvWrcsf8+///u9ZRGTd3d3FGrOk7NmzJzvjjDOyRx99NPuzP/uzfKBY+/HzxS9+MbvwwgvfdP/w8HDW0NCQ3XLLLflt/f39WVVVVfbtb3/7rRixZC1cuDD7y7/8yxHbFi1alC1evDjLMms/Xn4/UI5mnZ9//vksIrLNmzfnj/nxj3+clZWVZb/61a+O+rFL7iWeAwcORE9PT7S2tua3lZeXR2tra3R3dxdxstI2MDAQERG1tbUREdHT0xMHDx4c8X1obm6OpqYm34cCaW9vj4ULF45Y4whrP55+8IMfxJw5c+ITn/hETJs2Lc4999z4+te/nt+/ffv26O3tHbH2uVwu5s6da+3H6AMf+EB0dXXFL3/5y4iIeOaZZ+KJJ56IBQsWRIS1f6sczTp3d3dHTU1NzJkzJ39Ma2trlJeXx6ZNm476sYr+acaF9utf/zoOHTp02G+tra+vjxdeeKFIU5W24eHhWLZsWVxwwQVx9tlnR0REb29vVFZWHvbBj/X19dHb21uEKUvL2rVr46mnnorNmzcfts/aj5+XX3457r777ujo6Ii/+7u/i82bN8df//VfR2VlZSxZsiS/vkf6/8faj831118fg4OD0dzcHBMmTIhDhw7FzTffHIsXL46IsPZvkaNZ597e3pg2bdqI/RUVFVFbWzuq70XJBQpvvfb29njuuefiiSeeKPYoJ4SdO3fGddddF48++mhMmjSp2OOcUIaHh2POnDnx1a9+NSIizj333HjuuefinnvuiSVLlhR5utL23e9+N+6///5Ys2ZNvPe9742tW7fGsmXLYvr06da+RJXcSzwnn3xyTJgw4bArFvr6+qKhoaFIU5Wua665Jh566KH4yU9+Eqeddlp+e0NDQxw4cCD6+/tHHO/7MHY9PT2xe/fuOO+886KioiIqKipiw4YNceedd0ZFRUXU19db+3Fy6qmnxllnnTVi25lnnhk7duyIiMivr/9/Cu9v//Zv4/rrr49PfepT8b73vS8+85nPxPLly6OzszMirP1b5WjWuaGhIXbv3j1i///8z//Ea6+9NqrvRckFSmVlZcyePTu6urry24aHh6OrqytaWlqKOFlpybIsrrnmmnjggQfisccei5kzZ47YP3v27Jg4ceKI78O2bdtix44dvg9jdPHFF8ezzz4bW7duzd/mzJkTixcvzv/Z2o+PCy644LDL6X/5y1/G6aefHhERM2fOjIaGhhFrPzg4GJs2bbL2Y/T6669HefnIH1kTJkyI4eHhiLD2b5WjWeeWlpbo7++Pnp6e/DGPPfZYDA8Px9y5c4/+wcb8Ft8ErV27Nquqqsruu+++7Pnnn88+//nPZzU1NVlvb2+xRysZV199dZbL5bKf/vSn2auvvpq/vf766/ljrrrqqqypqSl77LHHsi1btmQtLS1ZS0tLEacuXb97FU+WWfvx8uSTT2YVFRXZzTffnL344ovZ/fffn5100knZt771rfwxK1euzGpqarLvf//72b/9279ll156qUtdC2DJkiXZH/3RH+UvM/7e976XnXzyydkXvvCF/DHWvjD27NmTPf3009nTTz+dRUR26623Zk8//XT2n//5n1mWHd06f/jDH87OPffcbNOmTdkTTzyRnXHGGS4zfsPXvva1rKmpKausrMzOP//8bOPGjcUeqaRExBFvq1evzh/z29/+Nvurv/qr7O1vf3t20kknZR/72MeyV199tXhDl7DfDxRrP37Wr1+fnX322VlVVVXW3Nyc/eu//uuI/cPDw9kNN9yQ1dfXZ1VVVdnFF1+cbdu2rUjTlo7BwcHsuuuuy5qamrJJkyZl73jHO7IvfelL2dDQUP4Ya18YP/nJT474//uSJUuyLDu6df7Nb36TXX755dmUKVOy6urq7Morr8z27NkzqjnKsux3fg0fAEACSu49KADA8U+gAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJCc/wfOtuyF2zL05wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "sim = torch.nn.CosineSimilarity(dim=-1)\n",
        "for i in range(q_size):\n",
        "  score = sim(tokenized_queries[i], tokenized_database[i])\n",
        "  if score >= 0.95:\n",
        "    count += 1\n",
        "    # print(score)\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "id": "4MMPNl586r22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7bf28f-6bd6-47ba-d033-cd89f5bcfd1f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58\n"
          ]
        }
      ]
    }
  ]
}